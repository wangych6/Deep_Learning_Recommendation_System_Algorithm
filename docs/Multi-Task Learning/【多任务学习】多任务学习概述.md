# 【多任务学习】多任务学习概述

很多业界推荐的业务，天然就是一个多目标的建模场景，需要多目标共同优化。以微信视频号推荐为例，打开一个视频，如图，首页上除了由于视频自动播放带来的“播放时长”、“完播率”（用户播放时长占视频长度的比例）目标之外，还有大量的互动标签，例如“点击好友头像”、“进入主页”、“关注”、“收藏”、“分享”、“点赞”、“评论”等。究竟哪一个标签最符合推荐系统的建模目标呢？

如果要用一个词来概括所有各式各样的推荐系统的终极目标，那就是“用户满意度”，但我们无法找到一个显示的指标量化用户满意度。业界一般使用“DAU”、“用户日均使用时长”、“留存率”来作为客观的间接的“用户满意度”（或者说算法工程师绩效）评价指标。而这些指标都是难以通过单一目标建模的，以使用时长为例，长视频播放长度天然大于短视频。所幸的是，虽然没有显式的用户满意度评价指标，但是现在的app都存在类似上述视频号推荐场景的丰富具体的隐式反馈。但这些独立的隐式反馈也存在一些挑战：

- 目标偏差：点赞、分享表达的满意度可能比播放要高
- 物品偏差：不同视频的播放时长体现的满意度不一样，有的视频可能哄骗用户看到尾部（类似新闻推荐中的标题党）
- 用户偏差：有的用户表达满意喜欢用点赞，有的用户可能喜欢用收藏

从业务角度想，假如我们一直在train完播率，会导致什么后果呢？模型会越来越倾向于推荐很短的视频，对长视频是非常不公平的。

因此我们需要使用多任务学习模型针对多个目标进行预测，并在线上融合多目标的预测结果进行排序。多任务学习也不能直接表达用户满意度，但是可以最大限度利用能得到的用户反馈信息进行充分的表征学习，并且可建模业务之间的关系，从而高效协同学习具体任务。

**二、为什么多任务学习有效？**

当把业务独立建模变成多任务联合建模之后，有可能带来四种结果：

![img](https://pic1.zhimg.com/80/v2-44927ccdd6caf9685d3d9d5367af98dc_1440w.jpg)

多任务学习的优势在于通过部分参数共享，联合训练，能在保证“还不错”的前提下，实现多目标共同提升。原因有以下几种：

- 任务互助：对于某个任务难学到的特征，可通过其他任务学习
- 隐式数据增强：不同任务有不同的噪声，一起学习可抵消部分噪声
- 学到通用表达，提高泛化能力：模型学到的是对所有任务都偏好的权重，有助于推广到未来的新任务
- 正则化：对于一个任务而言，其他任务的学习对该任务有正则化效果

**三、多任务学习都在研究什么问题**？

如上所述，多任务的核心优势在于通过不同任务的网络参数共享，实现1+1>2的提升，因此多任务学习的一大主流研究方向便是如何设计有效的网络结构。多个label的引入自然带来了多个loss，那么如何在联合训练中共同优化多个loss则是关键问题。

- 网络结构设计：主要研究哪些参数共享、在什么位置共享、如何共享。这一方向我们认为可以分为两大类，第一类是在设计网络结构时，考虑目标间的显式关系（例如淘宝中，点击之后才有购买行为发生），以阿里提出的ESMM为代表；另一类是目标间没有显示关系（例如短视频中的收藏与分享），在设计模型时不考虑label之间的量化关系，以谷歌提出的MMOE为代表。
- 多loss的优化策略：主要解决loss数值有大有小、学习速度有快有慢、更新方向时而相反的问题。最经典的两个工作有UWL（Uncertainty Weight）：通过自动学习任务的uncertainty，给uncertainty大的任务小权重，uncertainty小的任务大权重；GradNorm：结合任务梯度的二范数和loss下降梯度，引入带权重的损失函数Gradient Loss，并通过梯度下降更新该权重。

## 网络结构设计

![image-20220517223318058](/Users/chester/Desktop/Deep_Learning_Recommender_System /docs/imges/image-20220517223318058.png)

Architectures从网络结构设计方向思考哪些参数共享，在什么位置，如何共享。合理的共享网络结构设计对于效果提升有举足轻重的作用。至今，多任务的研究焦点依然在于如何结合任务来设计共享结。如上图，较为常见的结构有Share-Bottom【hard】，无需赘述。2018年google提出MMOE，将hard的参数共享变成多个expert，通过门控来控制不同loss对每个expert的影响，2019年google提出SNR，借助简单的 NAS（Neural Architecture Search)，对 Sub-Network 进行组合，为不同目标学习各自的网络结构。2020年tencent提出PLE，在MMOE的基础上增加了各任务独有的Expert。近年来，在多任务学习中建模任务间关系的研究取得了很大的进展。我们将这些主要研究分为两大类：

### 专家底类-MMoE、PLE

控制多任务模型底部的专家模块如何在任务间参数共享[1,2,3]，顶部的多塔模块分别处理每个任务，正如图3（a）所示，我们称这一类为**专家底（Expert-Bottom）**模式。然而，专家底模式只能在任务间传递浅层表示，但在靠近输出层的网络中往往包含更丰富、更有用的表示[4,5]，这已被证明能带来更多的增益[6]。另外，由于专家底模式不是专门为具有序列依赖的任务设计的，因此这些具有专家底模式的模型不能显式地对序列依赖进行建模。

这张图是PLE统计的主流的专家底类MTL任务模型设计思想：

![image-20220517210202710](/Users/chester/Desktop/Deep_Learning_Recommender_System /docs/imges/image-20220517210202710.png)

演进是朝着一个更加灵活的参数共享方向，思考为什么这样的演进可以带来效果的提升？我们常看到效果提升对解释是：不同的expert负责学习不同的信息内容，然后通过gate来组合这些信息，通过不同任务gate的softmax的热力分布差异，来表明expert对不同的目标各司其责，从而提升了效果。如果将视角从宏观切换到微观，从“更加灵活的参数共享”这个角度来看，MMoE对参数使用了“化整为零”的策略，PLE则是“化整为零+各有所得”。

MMoE做了一个聪明的事情，“化整为零”。把一个共享参数矩阵化成多个结合gate的共享Expert，这样不同的loss在存在相互冲突的时候，在不同的expert上，不同loss可以有相对强弱的表达，那么出现相互抵消的情况就可能减少，呈现出部分experts受某task影响较大，部分experts受其他task主导，这种“各有所得”的状态。但是MMoE并不保证“各有所得”，PLE增加了spcific experts，保障“各有所得”，能够在“共享参数”的撕扯争夺上，有了最基础的保障。

- Shared Bottom->MMoE：MMoE将shared bottom分解成多个Expert，然后通过门控网络自动控制不同任务对这些Expert的梯度贡献。
- MMoE->PLE：PLE在MMoE的基础上又为每个任务增加了自有的Expert，仅由本任务对其梯度更新。

- MMoE：Google KDD 2018，提出后就成为了CTR领域MTL的标配。

这个文章中，有一个非常有意思的做法：人工控制两个任务的相似度，然后观测不同网络结构在不同任务相似度的表现效果。得出一个结论：MMoE在多任务之间的的相关性（ relatedness ）比较低的时候，效果也能很不错。

如下图，首先OMoE 和 MMoE的效果都是明显好于Baseline，表明化整为零的Experts对效果提升有非常重要的作用。近一步，如果任务相关度非常高（Correlation = 1.0），则OMoE和MMoE的效果近似，但是如果任务相关度很低（Correlation = 0.5），则OMoE的效果相对于MMoE明显下降，说明MMoE中的Multi-gate的结构对于任务差异带来的冲突有一定的缓解作用。

- PLE ：Tencent RecSys 2020, 对MMoE的改进，结构简洁，效果显著。

在MMoE的基础上，为每个任务增加了自己的specific expert，上文中已经解释了为什么specific expert为什么有效。看下图右上角的子图，PLE是唯一做到多任务共赢“well done”。MMoE是唯一做到“还不错”【一平一涨】。其余方法是跷跷板现象。Hard Sharing是负迁移。观察在不同相似度的多任务上，PLE都表现优秀。

### 概率迁移类-ESMM、AITM

在不同任务的输出层中迁移概率[7,8,9,10]，如图3（b）所示，我们称之为**概率迁移（Probability-Transfer）**模式。概率迁移模式只能通过标量乘积传递简单的概率信息，而忽略了向量空间中更丰富、更有用的表示，导致了信息的损失。如果其中任何一个概率没有被准确预测，多个任务将会受到影响。



## 多Loss优化策略

Optimization Strategy多目标优化策略从loss、Gradient的视角去思考任务与任务之间的关系。在微观层面缓解梯度冲突，参数撕扯，在宏观层面达到多任务的balance。如下表列出了目前常见的方法【后文会详细介绍其中几种方法的原理和推导】。多任务的loss， 我们能想到的最简单的结合方式，就是多个任务的loss直接相加，得到整体的loss。我们一眼就能看出不合理的地方，因为每个任务loss的量级，每个任务本身的重要程度可能不一样，这样无脑相加，可能导致多任务学习被某个任务主导(比如量级特别大)，这样其他任务的loss起到的作用微妙，就可能产生对主导任务拟合效果很好，但是其他任务效果变差，也就是我们听到的"跷跷板"现象。

相对于loss直接相加的方式，这个loss函数对于每个任务的loss进行加权。这种方式允许我们手动调整每个任务的重要性程度。 这种方式至少有下面两个问题我们可以想到：

这个就想人工做特征工程那样，需要非常高深的经验和对任务的了解程度，才有可能把权重设置好， 并且一旦设置好了权重 w w w， 在整个训练周期就定死了
不同任务学习的难易程度不同，就会导致不同任务的收敛速度会不一样，比如A任务快收敛了，B任务仍然没训练好等，此时这种固定权重在训练某阶段可能限制任务的学习

### UWL

文章：《Multi-task learning using uncertainty to weigh losses for scene geometry and semantics》
这个文章估计是多目标Loss优化策略中，最常被提及的方法。但是目前在我们的任务上，没有取得明显的效果【ps. 据大多数使用过的同学反馈，都是没啥效果的】。
文章希望直接建模单个任务中的uncertainty，然后通过uncertainty来指导权重的调节。

### GradNorm

任务不平衡会阻碍模型的训练，而这种阻碍其实体现在了反向传播时参数的梯度不平衡。所以作者就考虑，能不能通过动态调整每个任务的loss权重，来让参数的梯度保持平衡呢？ 这类似于一种逆向思维的方式，答案当然是能。 作者提出的Grannorm方法非常的巧妙且实用，所以下面详细剖析下这种方法是啥，以及怎么自适应平衡多任务loss的。

我们既然是要在训练过程中根据各个任务的梯度量级和各个任务训练的速度去动态调整每个任务的权重嘛， 就得需要对比出每个任务的参数梯度到底是大还是小？ 每个任务目前训练的是快还是慢？

下面首先要定义一些变量来衡量任务的loss量级或者梯度量级，以及任务训练的快慢等。 这些都是Gradient Normalization算法的核心变量， 要好好理解。

1. W：网络最后一层参数；
2. G：W的梯度二范数，越大说明主导性越强；
3. G拔：G的平均值；
4. r：对第t次的loss和之前loss的比值，然后归一化；

所以更新策略是用r的a次方*G来更新G；

## 线上如何打分

根据什么指标进行排序？

![image-20220525192138954](/Users/chester/Desktop/Deep_Learning_Recommender_System /docs/imges/image-20220525192138954.png)



## 总结

1. ESMM、MMOE、PLE模型如何选择？

   - 个人经验，无论任务之间是否有依赖关系，皆可以优先尝试CGC。而多层CGC（即PLE）未必比CGC效果好，且在相同参数规模小，CGC普遍好于MMOE。对于相关性特别差的多任务，CGC相对MMOE而言有多个专有expert兜底。

   - 对于典型的label存在路径依赖的多任务，例如CTR与CVR，可尝试ESMM。

   - 而在业界的实践案例中，更多的是两种范式的模型进行融合。例如美团在其搜索多业务排序场景上提出的模型。

2. 多任务多目标出现跷跷板、负迁移现象，微观的梯度冲突是本质。不论是从Architecture 还是 Optimization strategy两个维度来优化升级，殊途同归，都是要缓解冲突，减少多任务间的内耗。

3. 总结一下，从实践角度来看，要做一个共赢的多任务多目标模型，技术层面几点经验tips：

（1）网络结构backbone，目前优选PLE；

（2）多任务的设计和构造，要考虑任务间的相似性；如主 + 辅任务，辅助任务和主任务的关系需要考虑；

- 目前还没有一种权威的方法或者指标来度量任务与任务之间的相似性，那么实操中，怎么办？【PS. 多任务间的相似性度量，应该也是一个有意思的研究点】
- 多任务两个Loss，只训练其中一个Loss，另一个Loss也在缓慢下降！ => 任务相关（get）
  - 三个loss，ctr/cvr/contra loss, 仅仅 training ctr/cvr主任务loss，观察另一个辅助contra loss也会跟随下降。实验表明引入这个辅助loss一起train会带来很好的离线效果提升。

1. （3）优化策略方面，留意多个Loss的量级，如果差异很大，注意约束和控制；上图contra loss 与 ctr cvr的loss，差了一个量级。

   （4）梯度冲突的解决，一种技能是pareto，另一种是以pcgrad为代表的直接对梯度进行调整的方法，可选用。

   多任务多目标的优化，有两种典型的方式：

   1. 主任务 + 主任务：解决业务场景既要又要的诉求；多个任务都要涨；
   2. 主任务 + 辅任务：辅助任务为主任务提供一些知识信息的增强，帮助主任务提升；

   不同的业务诉求下，会有任务目标不同的侧重、关联、取舍。多任务多目标，有非常多的组合盲盒，等待打开。

